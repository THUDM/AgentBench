gpt-3.5-turbo-0613:
    import: "./openai-chat.yaml"
    parameters:
        name: "gpt-3.5-turbo-0613"
        body:
            model: "gpt-3.5-turbo-0613"
            max_tokens: 512

text-davinci-003:
    import: "./openai-text.yaml"
    parameters:
        name: "text-davinci-003"
        body:
            model: "text-davinci-003"
            max_tokens: 512

text-davinci-002:
    import: "./openai-text.yaml"
    parameters:
        name: "text-davinci-002"
        body:
            model: "text-davinci-002"
            max_tokens: 512


gpt-4o-mini:
    import: "./openai-chat.yaml"
    parameters:
        name: "gpt-4o-mini"
        body:
            model: "gpt-4o-mini"
            
gpt-4o:
    import: "./openai-chat.yaml"
    parameters:
        name: "gpt-4o-2024-11-20"
        body:
            model: "gpt-4o-2024-11-20"

o1-mini:
    import: "./openai-chat.yaml"
    parameters:
        name: "o1-mini"
        body:
            model: "o1-mini"


gemini-2.0:
    import: "./gemini-chat.yaml"
    parameters:
        name: "gemini-2.0"
        body:
            model: "google/gemini-2.0-flash-exp"
            max_tokens: 2048


llama-3.3:
    import: "./together-chat.yaml"
    parameters:
        name: "llama-3.3"
        body:
            model: "meta-llama/Llama-3.3-70B-Instruct-Turbo"
            max_tokens: 2048

deepseekv3:
    import: "./together-chat.yaml"
    parameters:
        name: "deepseekv3"
        body:
            model: "deepseek-ai/DeepSeek-V3"
            max_tokens: 2048
